{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab77e60",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To predict the chances of patients getting a heart attack using the provided dataset, I'll follow these steps:\n",
    "\n",
    "1. **Data Loading and Preprocessing**: Load the dataset, handle missing values if any, and perform any necessary preprocessing steps like encoding categorical variables.\n",
    "2. **Exploratory Data Analysis (EDA)**: Analyze the dataset to understand the distribution of variables and the relationship between features and the target variable.\n",
    "3. **Model Selection**: Choose a suitable model for prediction. I'll consider logistic regression for this task due to its effectiveness in binary classification problems like this.\n",
    "4. **Model Training**: Train the model on the dataset.\n",
    "5. **Model Evaluation**: Evaluate the model using appropriate metrics like accuracy, precision, recall, and ROC-AUC.\n",
    "6. **Visualization**: Provide visualizations to interpret the model results and feature importance.\n",
    "\n",
    "Let's start by loading the dataset and performing some initial explorations to understand its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e815c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "heart_df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(heart_df.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(heart_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fd7b8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here's an overview of the dataset:\n",
    "\n",
    "{{outputs[0]}}\n",
    "\n",
    "And the summary statistics:\n",
    "\n",
    "{{outputs[1]}}\n",
    "\n",
    "### Observations:\n",
    "- The dataset contains 303 entries with no missing values across 14 features.\n",
    "- Features include age, sex, chest pain type (cp), resting blood pressure (trtbps), cholesterol levels (chol), fasting blood sugar (fbs), resting electrocardiographic results (restecg), maximum heart rate achieved (thalachh), exercise induced angina (exng), ST depression induced by exercise relative to rest (oldpeak), the slope of the peak exercise ST segment (slp), number of major vessels colored by fluoroscopy (caa), thalassemia (thall), and the target variable (output) indicating the presence of heart disease.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Data Preprocessing**: Check for any categorical variables that need encoding and scale the numerical features.\n",
    "2. **Exploratory Data Analysis (EDA)**: Visualize the data to understand the relationships between features.\n",
    "3. **Model Building**: Implement logistic regression for prediction.\n",
    "\n",
    "Let's proceed with data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89509c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Encoding categorical variables and scaling numerical features\n",
    "heart_df['sex'] = heart_df['sex'].astype('category')\n",
    "heart_df['cp'] = heart_df['cp'].astype('category')\n",
    "heart_df['fbs'] = heart_df['fbs'].astype('category')\n",
    "heart_df['restecg'] = heart_df['restecg'].astype('category')\n",
    "heart_df['exng'] = heart_df['exng'].astype('category')\n",
    "heart_df['slp'] = heart_df['slp'].astype('category')\n",
    "heart_df['caa'] = heart_df['caa'].astype('category')\n",
    "heart_df['thall'] = heart_df['thall'].astype('category')\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "heart_df[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']] = scaler.fit_transform(heart_df[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']])\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X = heart_df.drop('output', axis=1)\n",
    "y = heart_df['output']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Data preprocessing complete. Training and testing sets prepared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ba435",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Next Steps:\n",
    "1. **Exploratory Data Analysis (EDA)**: Visualize the relationships between features and the target variable.\n",
    "2. **Model Building**: Train a logistic regression model.\n",
    "\n",
    "Let's start with the exploratory data analysis to visualize some key relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed37906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Create a figure to hold the visualizations\n",
    "plt.figure(figsize=(20, 15), facecolor='white')\n",
    "\n",
    "# Plotting correlations\n",
    "plt.subplot(2, 2, 1)\n",
    "corr_matrix = heart_df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Age vs Max Heart Rate\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x='age', y='thalachh', hue='output', data=heart_df)\n",
    "plt.title('Age vs Max Heart Rate')\n",
    "\n",
    "# Cholesterol Levels vs Max Heart Rate\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x='chol', y='thalachh', hue='output', data=heart_df)\n",
    "plt.title('Cholesterol Levels vs Max Heart Rate')\n",
    "\n",
    "# ST Depression vs Heart Disease\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x='output', y='oldpeak', data=heart_df)\n",
    "plt.title('ST Depression vs Heart Disease')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffaae5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here are some visualizations from the exploratory data analysis:\n",
    "\n",
    "{{images[0]}}\n",
    "\n",
    "### Visualizations Explained:\n",
    "- **Correlation Matrix**: Shows the relationships between all numerical features. Some features like 'oldpeak' (ST depression) show a notable correlation with the target variable 'output'.\n",
    "- **Age vs Max Heart Rate**: Scatter plot showing how maximum heart rate achieved during exercise varies with age, colored by the presence of heart disease.\n",
    "- **Cholesterol Levels vs Max Heart Rate**: Scatter plot illustrating the relationship between cholesterol levels and maximum heart rate, also colored by heart disease status.\n",
    "- **ST Depression vs Heart Disease**: Box plot comparing the levels of ST depression in patients with and without heart disease.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Model Building**: Train a logistic regression model using the preprocessed data.\n",
    "2. **Model Evaluation**: Assess the model's performance on the testing set.\n",
    "\n",
    "Shall we proceed with building the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9484e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of the logistic regression model: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('\\nClassification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62501f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The logistic regression model has been trained and evaluated. Here are the results:\n",
    "\n",
    "- **Accuracy**: 85%\n",
    "- **Confusion Matrix**:\n",
    "  {{outputs[2]}}\n",
    "- **Classification Report**:\n",
    "  {{outputs[4]}}\n",
    "\n",
    "### Model Performance:\n",
    "- The model achieves an accuracy of 85%, indicating a good fit for the dataset.\n",
    "- The confusion matrix shows a balanced performance between false positives and false negatives.\n",
    "- The classification report provides detailed metrics like precision, recall, and F1-score for each class, showing a balanced performance across the board.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Model Tuning**: We could explore hyperparameter tuning to potentially improve the model.\n",
    "2. **Feature Importance**: Analyze which features are most influential in predicting heart disease.\n",
    "\n",
    "Would you like to proceed with any of these next steps or explore something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a2562",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's proceed with hyperparameter tuning for the logistic regression model to potentially improve its performance. We'll use grid search to explore different combinations of hyperparameters.\n",
    "\n",
    "I'll set up a grid search with cross-validation to find the best parameters for the logistic regression model. Let's start this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(random_state=42), param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters found: {best_params}')\n",
    "print(f'Best cross-validated accuracy: {best_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2c6b8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The hyperparameter tuning using grid search has completed. Here are the results:\n",
    "\n",
    "- **Best Parameters**: \n",
    "  - Regularization Strength (C): 1\n",
    "  - Maximum Iterations (max_iter): 100\n",
    "  - Solver: liblinear\n",
    "- **Best Cross-Validated Accuracy**: 83%\n",
    "\n",
    "Interestingly, the best cross-validated accuracy (83%) is slightly lower than the accuracy we achieved earlier (85%). This could be due to the model being more generalized when using cross-validation, which often provides a more realistic estimate of model performance on unseen data.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Re-train Model**: We can re-train the model using these optimized parameters and evaluate it again.\n",
    "2. **Feature Importance Analysis**: Analyze which features are most influential in predicting heart disease.\n",
    "\n",
    "Would you like to re-train the model with these parameters, or would you prefer to explore the feature importance analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4828c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Explore feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf37ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the logistic regression model with the best parameters\n",
    "optimized_logreg = LogisticRegression(C=1, max_iter=100, solver='liblinear', random_state=42)\n",
    "optimized_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients of the features\n",
    "feature_importance = optimized_logreg.coef_[0]\n",
    "\n",
    "# Create a DataFrame to view the feature importance\n",
    "importance_df = pd.DataFrame(feature_importance, index=X_train.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b4c51",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here is the feature importance analysis based on the coefficients from the optimized logistic regression model:\n",
    "\n",
    "{{outputs[0]}}\n",
    "\n",
    "### Feature Importance Insights:\n",
    "- **Positive Coefficients** indicate features that increase the likelihood of heart disease:\n",
    "  - **cp (Chest Pain Type)**: Strongest positive influence.\n",
    "  - **slp (Slope of the peak exercise ST segment)**: Significant positive influence.\n",
    "  - **restecg (Resting electrocardiographic results)**: Moderate positive influence.\n",
    "  - **thalachh (Maximum heart rate achieved)**: Some positive influence.\n",
    "  - **fbs (Fasting blood sugar > 120 mg/dl)**: Slight positive influence.\n",
    "\n",
    "- **Negative Coefficients** indicate features that decrease the likelihood of heart disease:\n",
    "  - **sex (Gender)**: Strongest negative influence.\n",
    "  - **exng (Exercise induced angina)**: Significant negative influence.\n",
    "  - **caa (Number of major vessels colored by flourosopy)**: Moderate negative influence.\n",
    "  - **oldpeak (ST depression induced by exercise relative to rest)**: Moderate negative influence.\n",
    "  - **thall (Thalassemia)**: Moderate negative influence.\n",
    "  - **trtbps (Resting blood pressure)**: Some negative influence.\n",
    "  - **chol (Serum Cholestoral)**: Slight negative influence.\n",
    "  - **age**: Very slight negative influence.\n",
    "\n",
    "### Conclusion:\n",
    "The model suggests that certain types of chest pain, a higher maximum heart rate, and certain ECG results are associated with a higher likelihood of heart disease, while factors like being male, having exercise-induced angina, and having more major vessels visible on fluoroscopy are associated with a lower likelihood.\n",
    "\n",
    "Would you like to delve deeper into any specific feature or proceed with another analysis?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
